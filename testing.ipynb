{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from config import *\n",
    "import torch\n",
    "from dataloaders import CNNDataset\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CNNDataset(data_csv=P_TRAIN_CSV, target_csv=P_TARGETS_CSV, matrix_dir=ETERNA_PKG_BPP )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator1 = torch.Generator().manual_seed(42)\n",
    "train_dataset, val_dataset = random_split(dataset, [0.7, 0.3], generator1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143378    DATA/stanford-ribonanza-rna-folding/Ribonanza_...\n",
       "Name: path, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.matrix_df[dataset.matrix_df['sequence_id'] == '00257e85caac']['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, persistent_workers=True)  \n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4, persistent_workers=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_dataloader:\n",
    "    print(x.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "(207,)\n",
      "Shape of reactivity:  torch.Size([223])\n",
      "after function shape: torch.Size([224, 224])\n",
      "Shape of matrix:  torch.Size([224, 224])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         -3.6000e-02,  6.8300e-01,  1.8900e-01, -5.0000e-03, -3.9000e-02,\n",
       "         -1.7000e-02,  2.7000e-02, -7.0000e-03,  1.4800e-01,  2.8000e-02,\n",
       "         -1.4400e-01, -6.1000e-02, -7.3000e-02,  9.0000e-03,  0.0000e+00,\n",
       "          2.8000e-02, -3.4000e-02, -1.0900e-01, -2.5600e-01,  7.8000e-02,\n",
       "          2.8400e-01,  3.6100e-01,  6.3100e-01, -2.7000e-02, -2.9000e-02,\n",
       "          7.6000e-02,  5.1500e-01,  1.6900e-01,  2.0000e-01,  1.2000e-02,\n",
       "          2.6300e-01,  4.7700e-01,  5.3100e-01,  2.2830e+00,  9.8100e-01,\n",
       "          2.8210e+00,  1.5500e-01, -1.9100e-01,  3.0000e-03,  2.0000e-02,\n",
       "          4.1400e-01,  2.6200e-01,  1.8600e-01,  1.1380e+00, -1.5700e-01,\n",
       "          8.5000e-02, -4.0000e-02, -8.0000e-03, -7.7000e-02, -1.0400e-01,\n",
       "         -7.9000e-02, -4.1000e-02,  1.9300e-01, -1.2000e-02,  1.8000e-02,\n",
       "          4.4800e-01, -4.4000e-02,  3.0300e-01, -6.4000e-02,  6.3000e-02,\n",
       "         -7.0000e-03, -2.0500e-01, -6.5000e-02, -9.7000e-02, -2.6000e-02,\n",
       "         -1.7300e-01, -3.6000e-02, -3.2900e-01,  1.1000e-01,  0.0000e+00,\n",
       "          2.0000e-03,  2.8200e-01,  2.3100e-01,  2.8200e-01,  1.2300e-01,\n",
       "         -6.8000e-02,  1.0500e-01, -5.0000e-03, -1.2800e-01, -1.0300e-01,\n",
       "          9.3000e-02, -2.7000e-02, -1.0800e-01,  1.1200e-01, -5.3000e-02,\n",
       "         -9.7000e-02, -7.3000e-02,  8.8000e-02,  4.9000e-02,  0.0000e+00,\n",
       "         -1.5000e-02,  1.0000e-02,  9.0000e-03,  0.0000e+00,  3.1300e-01,\n",
       "          3.2900e-01,  8.2300e-01,  1.8130e+00,  4.8400e-01,  6.1100e-01,\n",
       "          5.2400e-01,  4.5300e-01,  5.6600e-01,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## credits to https://github.com/GitYCC/crnn-pytorch/blob/master/src/model.py\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "\n",
    "class CRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, img_channel, img_height, img_width,\n",
    "                 map_to_seq_hidden=64, rnn_hidden=256, leaky_relu=False):\n",
    "        super(CRNN, self).__init__()\n",
    "\n",
    "        self.cnn, (output_channel, output_height, output_width) = \\\n",
    "            self._cnn_backbone(img_channel, img_height, img_width, leaky_relu)\n",
    "\n",
    "        self.map_to_seq = nn.Linear(output_channel * output_height, map_to_seq_hidden)\n",
    "\n",
    "        self.rnn1 = nn.LSTM(map_to_seq_hidden, rnn_hidden, bidirectional=True)\n",
    "        self.rnn2 = nn.LSTM(2 * rnn_hidden, rnn_hidden, bidirectional=True)\n",
    "\n",
    "        self.dense = nn.Linear(2 * rnn_hidden, 1)\n",
    "\n",
    "    def _cnn_backbone(self, img_channel, img_height, img_width, leaky_relu):\n",
    "        assert img_height % 16 == 0\n",
    "        assert img_width % 4 == 0\n",
    "\n",
    "        channels = [img_channel, 64, 128, 256, 256, 512, 512, 512]\n",
    "        kernel_sizes = [3, 3, 3, 3, 3, 3, 2]\n",
    "        strides = [1, 1, 1, 1, 1, 1, 1]\n",
    "        paddings = [1, 1, 1, 1, 1, 1, 0]\n",
    "\n",
    "        cnn = nn.Sequential()\n",
    "\n",
    "        def conv_relu(i, batch_norm=False):\n",
    "            # shape of input: (batch, input_channel, height, width)\n",
    "            input_channel = channels[i]\n",
    "            output_channel = channels[i+1]\n",
    "\n",
    "            cnn.add_module(\n",
    "                f'conv{i}',\n",
    "                nn.Conv2d(input_channel, output_channel, kernel_sizes[i], strides[i], paddings[i])\n",
    "            )\n",
    "\n",
    "            if batch_norm:\n",
    "                cnn.add_module(f'batchnorm{i}', nn.BatchNorm2d(output_channel))\n",
    "\n",
    "            relu = nn.LeakyReLU(0.2, inplace=True) if leaky_relu else nn.ReLU(inplace=True)\n",
    "            cnn.add_module(f'relu{i}', relu)\n",
    "\n",
    "        # size of image: (channel, height, width) = (img_channel, img_height, img_width)\n",
    "        conv_relu(0)\n",
    "        \n",
    "        cnn.add_module('pooling0', nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)))\n",
    "        # (64, img_height, img_width // 2)\n",
    "\n",
    "        conv_relu(1)\n",
    "        cnn.add_module('pooling1', nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)))\n",
    "        # (128, img_height , img_width // 4)\n",
    "\n",
    "        conv_relu(2)\n",
    "        conv_relu(3)\n",
    "        cnn.add_module(\n",
    "            'pooling2',\n",
    "            nn.MaxPool2d(kernel_size=(2, 1), kernel_sizes=(3,1))\n",
    "        )  # (256, img_height, img_width // 12)\n",
    "\n",
    "        conv_relu(4, batch_norm=True)\n",
    "        conv_relu(5, batch_norm=True)\n",
    "        cnn.add_module(\n",
    "            'pooling3',\n",
    "            nn.MaxPool2d(kernel_size=(2, 1), kernel_sizes=(19,1))\n",
    "        )  # (512, img_height // 16, img_width // 4)\n",
    "\n",
    "        conv_relu(6)  # (512, img_height // 16 - 1, img_width // 4 - 1)\n",
    "\n",
    "        output_channel, output_height, output_width = \\\n",
    "            channels[-1], img_height // 16 - 1, img_width // 4 - 1\n",
    "        return cnn, (output_channel, output_height, output_width)\n",
    "\n",
    "    def forward(self, images):\n",
    "        # shape of images: (batch, channel, height, width)\n",
    "        print(images.size)\n",
    "        conv = self.cnn(images)\n",
    "        batch, channel, height, width = conv.size()\n",
    "\n",
    "        conv = conv.view(batch, channel * height, width)\n",
    "        conv = conv.permute(2, 0, 1)  # (width, batch, feature)\n",
    "        seq = self.map_to_seq(conv)\n",
    "\n",
    "        recurrent, _ = self.rnn1(seq)\n",
    "        recurrent, _ = self.rnn2(recurrent)\n",
    "\n",
    "        self.output = self.dense(recurrent)\n",
    "        return self.output  # shape: (seq_len, batch, num_class)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from crnn import CRNN\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "from torch.nn import CTCLoss\n",
    "\n",
    "from dataloaders import CNNDataset\n",
    "from config import *\n",
    "\n",
    "\n",
    "# 📉 Define loss functions for training and evaluation\n",
    "def loss_fn(output, target):\n",
    "    # 🪟 Clip the target values to be within the range [0, 1]\n",
    "    clipped_target = torch.clip(target, min=0, max=1)\n",
    "    # 📉 Calculate the mean squared error loss\n",
    "    mses = F.mse_loss(output, clipped_target, reduction='mean')\n",
    "    return mses\n",
    "\n",
    "def mae_fn(output, target):\n",
    "    # 🪟 Clip the target values to be within the range [0, 1]\n",
    "    clipped_target = torch.clip(target, min=0, max=1)\n",
    "    # 📉 Calculate the mean absolute error loss\n",
    "    maes = F.l1_loss(output, clipped_target, reduction='mean')\n",
    "    return maes\n",
    "\n",
    "def train_batch(crnn, data, optimizer, criterion, device):\n",
    "    crnn.train()\n",
    "    images, targets= [d.to(device) for d in data]\n",
    "    logits = crnn(images)\n",
    "    #log_probs = torch.nn.functional.log_softmax(logits, dim=2)\n",
    "    log_probs = logits\n",
    "\n",
    "    batch_size = images.size(0)\n",
    "    input_lengths = torch.LongTensor([logits.size(0)] * batch_size)\n",
    "    target_lengths = torch.flatten(target_lengths)\n",
    "\n",
    "    loss = criterion(log_probs, targets)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(crnn.parameters(), 5) # gradient clipping with 5\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def main():\n",
    "    epochs = 1\n",
    "    #dataset = CNNDataset(data_csv=P_TRAIN_CSV, target_csv=P_TARGETS_CSV, matrix_dir=ETERNA_PKG_BPP )\n",
    "    generator1 = torch.Generator().manual_seed(42)\n",
    "    #train_dataset, val_dataset = random_split(dataset, [0.7, 0.3], generator1)\n",
    "    #dataset = CNNDataset(data_csv=P_TRAIN_CSV, target_csv=P_TARGETS_CSV, matrix_dir=ETERNA_PKG_BPP )\n",
    "    #train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, persistent_workers=True)  \n",
    "    #val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4, persistent_workers=True) \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'device: {device}')\n",
    "\n",
    "    model = CRNN(img_channel=1, img_width=224, img_height=224)\n",
    "    print(model)\n",
    "    #if reload_checkpoint:\n",
    "    #    crnn.load_state_dict(torch.load(reload_checkpoint, map_location=device))\n",
    "    model.to(device)\n",
    "\n",
    "    # 📈 Define the optimizer with learning rate and weight decay\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0003, weight_decay=5e-4)\n",
    "\n",
    "    # 🚂 Iterate over epochs\n",
    "    for epoch in range(epochs):\n",
    "        train_losses = []\n",
    "        train_maes = []\n",
    "        model.train()\n",
    "        \n",
    "        # 🚞 Iterate over batches in the training dataloader\n",
    "        for batch in (pbar := tqdm(train_dataloader, position=0, leave=True)):\n",
    "            loss = train_batch(model, batch, optimizer,loss_fn, device)\n",
    "            mae = mae_fn(out[batch.valid_mask], batch.y[batch.valid_mask])\n",
    "            loss.backward()\n",
    "            train_losses.append(loss.detach().cpu().numpy())\n",
    "            train_maes.append(mae.detach().cpu().numpy())\n",
    "            optimizer.step()\n",
    "            pbar.set_description(f\"Train loss {loss.detach().cpu().numpy():.4f}\")\n",
    "        \n",
    "        # 📊 Print average training loss and MAE for the epoch\n",
    "        print(f\"Epoch {epoch} train loss: \", np.mean(train_losses))\n",
    "        print(f\"Epoch {epoch} train mae: \", np.mean(train_maes))\n",
    "        \n",
    "        val_losses = []\n",
    "        val_maes = []\n",
    "        model.eval()\n",
    "        \n",
    "        # 🚞 Iterate over batches in the validation dataloader\n",
    "        for batch in (pbar := tqdm(val_dataloader, position=0, leave=True)):\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(batch.x, batch.edge_index)\n",
    "            out = torch.squeeze(out)\n",
    "            loss = loss_fn(out[batch.valid_mask], batch.y[batch.valid_mask])\n",
    "            mae = mae_fn(out[batch.valid_mask], batch.y[batch.valid_mask])\n",
    "            val_losses.append(loss.detach().cpu().numpy())\n",
    "            val_maes.append(mae.detach().cpu().numpy())\n",
    "            pbar.set_description(f\"Validation loss {loss.detach().cpu().numpy():.4f}\")\n",
    "        \n",
    "        # 📊 Print average validation loss and MAE for the epoch\n",
    "        print(f\"Epoch {epoch} val loss: \", np.mean(val_losses))\n",
    "        print(f\"Epoch {epoch} val mae: \", np.mean(val_maes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2159 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "max_pool1d: Expected 2D or 3D (batch mode) tensor with optional 0 dim batch size for input, but got:[64, 64, 224, 224]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/Mina/workspace/RNA_Reactivity_Prediction/testing.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Mina/workspace/RNA_Reactivity_Prediction/testing.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m main()\n",
      "\u001b[1;32m/Users/Mina/workspace/RNA_Reactivity_Prediction/testing.ipynb Cell 10\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Mina/workspace/RNA_Reactivity_Prediction/testing.ipynb#X12sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m \u001b[39m# 🚞 Iterate over batches in the training dataloader\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Mina/workspace/RNA_Reactivity_Prediction/testing.ipynb#X12sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m (pbar \u001b[39m:=\u001b[39m tqdm(train_dataloader, position\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, leave\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Mina/workspace/RNA_Reactivity_Prediction/testing.ipynb#X12sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m     loss \u001b[39m=\u001b[39m train_batch(model, batch, optimizer,loss_fn, device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Mina/workspace/RNA_Reactivity_Prediction/testing.ipynb#X12sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m     mae \u001b[39m=\u001b[39m mae_fn(out[batch\u001b[39m.\u001b[39mvalid_mask], batch\u001b[39m.\u001b[39my[batch\u001b[39m.\u001b[39mvalid_mask])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Mina/workspace/RNA_Reactivity_Prediction/testing.ipynb#X12sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "\u001b[1;32m/Users/Mina/workspace/RNA_Reactivity_Prediction/testing.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Mina/workspace/RNA_Reactivity_Prediction/testing.ipynb#X12sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m crnn\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Mina/workspace/RNA_Reactivity_Prediction/testing.ipynb#X12sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m images, targets\u001b[39m=\u001b[39m [d\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m data]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Mina/workspace/RNA_Reactivity_Prediction/testing.ipynb#X12sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m logits \u001b[39m=\u001b[39m crnn(images)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Mina/workspace/RNA_Reactivity_Prediction/testing.ipynb#X12sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m#log_probs = torch.nn.functional.log_softmax(logits, dim=2)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Mina/workspace/RNA_Reactivity_Prediction/testing.ipynb#X12sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m log_probs \u001b[39m=\u001b[39m logits\n",
      "File \u001b[0;32m~/miniconda3/envs/rna/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/rna/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/RNA_Reactivity_Prediction/crnn.py:82\u001b[0m, in \u001b[0;36mCRNN.forward\u001b[0;34m(self, images)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, images):\n\u001b[1;32m     80\u001b[0m     \u001b[39m# shape of images: (batch, channel, height, width)\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m     conv \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcnn(images)\n\u001b[1;32m     83\u001b[0m     batch, channel, height, width \u001b[39m=\u001b[39m conv\u001b[39m.\u001b[39msize()\n\u001b[1;32m     85\u001b[0m     conv \u001b[39m=\u001b[39m conv\u001b[39m.\u001b[39mview(batch, channel \u001b[39m*\u001b[39m height, width)\n",
      "File \u001b[0;32m~/miniconda3/envs/rna/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/rna/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/rna/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/rna/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/rna/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/rna/lib/python3.10/site-packages/torch/nn/modules/pooling.py:92\u001b[0m, in \u001b[0;36mMaxPool1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor):\n\u001b[0;32m---> 92\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mmax_pool1d(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_size, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m     93\u001b[0m                         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, ceil_mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mceil_mode,\n\u001b[1;32m     94\u001b[0m                         return_indices\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreturn_indices)\n",
      "File \u001b[0;32m~/miniconda3/envs/rna/lib/python3.10/site-packages/torch/_jit_internal.py:488\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[39mreturn\u001b[39;00m if_true(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    487\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 488\u001b[0m     \u001b[39mreturn\u001b[39;00m if_false(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/rna/lib/python3.10/site-packages/torch/nn/functional.py:705\u001b[0m, in \u001b[0;36m_max_pool1d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mif\u001b[39;00m stride \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     stride \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mannotate(List[\u001b[39mint\u001b[39m], [])\n\u001b[0;32m--> 705\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mmax_pool1d(\u001b[39minput\u001b[39;49m, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: max_pool1d: Expected 2D or 3D (batch mode) tensor with optional 0 dim batch size for input, but got:[64, 64, 224, 224]"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = pd.read_csv(P_TARGETS_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.iloc[0, :-1].values.astype('float32').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 'DATA/Ribonanza_bpp_files/extra_data/9/8/2/ff4dcd9bf671.txt'\n",
    "import numpy as np\n",
    "\n",
    "# Load the data from the file\n",
    "data = np.loadtxt(test)\n",
    "\n",
    "# Determine the shape of the array\n",
    "max_row = int(data[:, 0].max())\n",
    "max_col = int(data[:, 1].max())\n",
    "\n",
    "# Create an empty array filled with zeros\n",
    "filled_array = np.zeros((max_row, max_col))\n",
    "\n",
    "# Fill the values from the loaded data into the empty array\n",
    "for row, col, value in data:\n",
    "    filled_array[int(row) - 1, int(col) - 1] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(191, 207)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_array.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dara = pd.read_csv(P_TRAIN_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_list = []\n",
    "file_paths = []\n",
    "for root, dirs, files in os.walk(ETERNA_PKG_BPP):\n",
    "    for file in files:\n",
    "        if file.endswith('.txt'):\n",
    "            file_list.append(os.path.join(root, file))\n",
    "            file_paths.append(file[:-4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_df = pd.DataFrame(columns=['sequence_id', 'path'])\n",
    "matrix_df['sequence_id'] = file_paths\n",
    "matrix_df['path'] = file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1915372"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(matrix_df['sequence_id'].to_list()) - set(targets['sequence_id'].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_df.drop(matrix_df['sequence_id']!=targets['sequence_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_path = dataset.matrix_df[dataset.matrix_df['sequence_id'] == '00257e85caac']['path'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
