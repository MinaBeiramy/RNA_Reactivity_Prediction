{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from config import *\n",
    "import torch\n",
    "from dataloaders.crnn_dataloader import *\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from torch.masked import masked_tensor, as_masked_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(\"-inf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_quick = pl.read_parquet(P_TRAIN_PARQUET_QUICK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_quick.columns[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recomended Approach: USE parquets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_dataset = ParquetCRNNDataset(P_TRAIN_PARQUET_QUICK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('GGGAACGACUCGAGUAGAGUCGAAAAGACCAUGAGGCCUUGACCGAUCGCGAGUUGGCCUGGUCGCAGACCGACUUCCCAAGCGAAGCUCCGGCGCGUUUCGAGGGCGACUCGUAUAACGAAGGCGGGUAGAGACGGCAUUCGUGCCGUCUCUACCAAAAGAAACAACAACAACAAC',\n",
       " 'DATA\\\\Ribonanza_bpp_files\\\\extra_data\\\\5\\\\8\\\\b\\\\0ab0ec3d057c.txt',\n",
       " 177)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parquet_dataset.sequence_df.row(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator1 = torch.Generator().manual_seed(42)\n",
    "train_dataset, val_dataset = random_split(parquet_dataset, [0.7, 0.3], generator1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4, persistent_workers=True, pin_memory=True)  \n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4, persistent_workers=True, pin_memory=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1647"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y , m = train_dataset.__getitem__(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_dataset)):\n",
    "    x, y, m = train_dataset.__getitem__(i)  \n",
    "    if y.shape[0] != 512:\n",
    "        print(i, y.shape) \n",
    "        break\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 512])\n"
     ]
    }
   ],
   "source": [
    "for x, y , z in train_dataloader:\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = InferenceParquetCRNNDataset(P_TEST_PARQUET, train_test_flag='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.__getitem__(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4, persistent_workers=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OPTTIONAL: use pandas \n",
    "uncomment if necessary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv(P_TRAIN_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = CNNDataset(data_csv=P_TRAIN_CSV, target_csv=P_TARGETS_CSV, matrix_dir=ETERNA_PKG_BPP )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.matrix_df[dataset.matrix_df['sequence_id'] == 'eee73c1836bc']['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator1 = torch.Generator().manual_seed(42)\n",
    "# train_dataset, val_dataset = random_split(parquet_dataset, [0.7, 0.3], generator1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, persistent_workers=True)  \n",
    "# val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4, persistent_workers=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test_dataset = CNNDataset(data_csv=P_TEST_CSV, train_test_flag='test', matrix_dir=ETERNA_PKG_BPP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataloader = DataLoader(test_dataset, batch_size=512, shuffle=False, num_workers=8, persistent_workers=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test_dataset.matrix_df[test_dataset.matrix_df['sequence_id'] == 'eee73c1836bc']['path'].values[0]\n",
    "#test_dataset.matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x, y in train_dataloader:\n",
    "#     print(x.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# import os\n",
    "# from tqdm import tqdm\n",
    "# import torch\n",
    "# from torch.utils.data import DataLoader, random_split\n",
    "# import torch.optim as optim\n",
    "# from torch.nn import CTCLoss\n",
    "\n",
    "# from dataloaders import CNNDataset\n",
    "# from config import *\n",
    "\n",
    "\n",
    "# # ðŸ“‰ Define loss functions for training and evaluation\n",
    "# def loss_fn(output, target):\n",
    "#     # ðŸªŸ Clip the target values to be within the range [0, 1]\n",
    "#     clipped_target = torch.clip(target, min=0, max=1)\n",
    "#     # ðŸ“‰ Calculate the mean squared error loss\n",
    "#     mses = F.l1_loss(output, clipped_target, reduction='mean')\n",
    "#     return mses\n",
    "\n",
    "# # def mae_fn(output, target):\n",
    "# #     # ðŸªŸ Clip the target values to be within the range [0, 1]\n",
    "# #     clipped_target = torch.clip(target, min=0, max=1)\n",
    "# #     # ðŸ“‰ Calculate the mean absolute error loss\n",
    "# #     maes = F.l1_loss(output, clipped_target, reduction='mean')\n",
    "# #     return maes\n",
    "\n",
    "# def train_batch(crnn, data, optimizer, criterion, device):\n",
    "#     #crnn.train()\n",
    "\n",
    "#     images, targets= [d.to(device) for d in data]\n",
    "\n",
    "#     logits = crnn(images)\n",
    "#     #log_probs = torch.nn.functional.log_softmax(logits, dim=2)\n",
    "#     log_probs = logits\n",
    "\n",
    "#     #atch_size = images.size(0)\n",
    "#     #input_lengths = torch.LongTensor([logits.size(0)] * batch_size)\n",
    "#     #target_lengths = torch.flatten(input_lengths)\n",
    "\n",
    "#     loss = criterion(log_probs, targets)\n",
    "\n",
    "#     optimizer.zero_grad()\n",
    "#     loss.backward()\n",
    "#     torch.nn.utils.clip_grad_norm_(crnn.parameters(), 5) # gradient clipping with 5\n",
    "#     optimizer.step()\n",
    "#     return loss.item()\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     epochs = 1\n",
    "#     #dataset = CNNDataset(data_csv=P_TRAIN_CSV, target_csv=P_TARGETS_CSV, matrix_dir=ETERNA_PKG_BPP )\n",
    "#     generator1 = torch.Generator().manual_seed(42)\n",
    "#     #train_dataset, val_dataset = random_split(dataset, [0.7, 0.3], generator1)\n",
    "#     #dataset = CNNDataset(data_csv=P_TRAIN_CSV, target_csv=P_TARGETS_CSV, matrix_dir=ETERNA_PKG_BPP )\n",
    "#     #train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, persistent_workers=True)  \n",
    "#     #val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4, persistent_workers=True) \n",
    "#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#     model = CRNN(img_channel=1, img_width=224, img_height=224)\n",
    "#     print(model)\n",
    "#     #if reload_checkpoint:\n",
    "#     #    crnn.load_state_dict(torch.load(reload_checkpoint, map_location=device))\n",
    "#     model.to(device)\n",
    "\n",
    "#     # ðŸ“ˆ Define the optimizer with learning rate and weight decay\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=0.0003, weight_decay=5e-4)\n",
    "\n",
    "#     # ðŸš‚ Iterate over epochs\n",
    "#     for epoch in range(epochs):\n",
    "#         train_losses = []\n",
    "#         model.train()\n",
    "        \n",
    "#         # ðŸšž Iterate over batches in the training dataloader\n",
    "#         for batch in (pbar := tqdm(train_dataloader, position=0, leave=True)):\n",
    "#             loss = train_batch(model, batch, optimizer, loss_fn, device)\n",
    "#             train_losses.append(loss.detach().cpu().numpy())\n",
    "#             pbar.set_description(f\"Train loss {loss.detach().cpu().numpy():.4f}\")\n",
    "        \n",
    "#         # ðŸ“Š Print average training loss and MAE for the epoch\n",
    "#         print(f\"Epoch {epoch} train loss: \", np.mean(train_losses))\n",
    "        \n",
    "#         val_losses = []\n",
    "#         model.eval()\n",
    "        \n",
    "#         # ðŸšž Iterate over batches in the validation dataloader\n",
    "#         for batch in (pbar := tqdm(val_dataloader, position=0, leave=True)):\n",
    "#             loss = train_batch(model, batch, optimizer, loss_fn, device)\n",
    "#             optimizer.zero_grad()\n",
    "#             out = model(batch.x, batch.edge_index)\n",
    "#             out = torch.squeeze(out)\n",
    "#             val_losses.append(loss.detach().cpu().numpy())\n",
    "#             pbar.set_description(f\"Validation loss {loss.detach().cpu().numpy():.4f}\")\n",
    "        \n",
    "#         # ðŸ“Š Print average validation loss and MAE for the epoch\n",
    "#         print(f\"Epoch {epoch} val loss: \", np.mean(val_losses))\n",
    "#         print(f\"Epoch {epoch} val mae: \", np.mean(val_maes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets.iloc[0, :-1].values.astype('float32').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = 'DATA/Ribonanza_bpp_files/extra_data/9/8/2/ff4dcd9bf671.txt'\n",
    "# import numpy as np\n",
    "\n",
    "# # Load the data from the file\n",
    "# data = np.loadtxt(test)\n",
    "\n",
    "# # Determine the shape of the array\n",
    "# max_row = int(data[:, 0].max())\n",
    "# max_col = int(data[:, 1].max())\n",
    "\n",
    "# # Create an empty array filled with zeros\n",
    "# filled_array = np.zeros((max_row, max_col))\n",
    "\n",
    "# # Fill the values from the loaded data into the empty array\n",
    "# for row, col, value in data:\n",
    "#     filled_array[int(row) - 1, int(col) - 1] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torchvision import models\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.utilities.types import STEP_OUTPUT\n",
    "from torchvision import models\n",
    "from torchmetrics.classification import F1Score, AUROC, Recall, ROC, Accuracy, Precision, Specificity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class CRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, img_channel, img_height, img_width,\n",
    "                 map_to_seq_hidden=64, rnn_hidden=256, leaky_relu=False):\n",
    "        super(CRNN, self).__init__()\n",
    "\n",
    "        self.cnn, (output_channel, output_height, output_width) = \\\n",
    "            self._cnn_backbone(img_channel, img_height, img_width, leaky_relu)\n",
    "\n",
    "        self.map_to_seq = nn.Linear(output_channel * output_height, map_to_seq_hidden)\n",
    "\n",
    "        self.rnn1 = nn.LSTM(map_to_seq_hidden, rnn_hidden, bidirectional=True)\n",
    "        self.rnn2 = nn.LSTM(2 * rnn_hidden, rnn_hidden, bidirectional=True)\n",
    "\n",
    "        self.dense = nn.Linear(2 * rnn_hidden, 1)\n",
    "  \n",
    "       \n",
    "\n",
    "    def _cnn_backbone(self, img_channel, img_height, img_width, leaky_relu):\n",
    "        assert img_height % 16 == 0\n",
    "        assert img_width % 4 == 0\n",
    "\n",
    "        channels = [img_channel, 64, 128, 256, 256, 512, 512, 512]\n",
    "        kernel_sizes = [3, 3, 3, 3, 3, 3, 3]\n",
    "        strides = [1, 1, 1, 1, 1, 1, 1]\n",
    "        paddings = [1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "        cnn = nn.Sequential()\n",
    "\n",
    "        def conv_relu(i, batch_norm=False):\n",
    "            # shape of input: (batch, input_channel, height, width)\n",
    "            input_channel = channels[i]\n",
    "            output_channel = channels[i+1]\n",
    "\n",
    "            cnn.add_module(\n",
    "                f'conv{i}',\n",
    "                nn.Conv2d(input_channel, output_channel, kernel_sizes[i], strides[i], paddings[i])\n",
    "            )\n",
    "\n",
    "            if batch_norm:\n",
    "                cnn.add_module(f'batchnorm{i}', nn.BatchNorm2d(output_channel))\n",
    "\n",
    "            relu = nn.LeakyReLU(0.2, inplace=True) if leaky_relu else nn.ReLU(inplace=True)\n",
    "            cnn.add_module(f'relu{i}', relu)\n",
    "\n",
    "        # size of image: (channel, height, width) = (img_channel, img_height, img_width)\n",
    "        conv_relu(0)\n",
    "        cnn.add_module('pooling0', nn.MaxPool2d(kernel_size=(2,1), stride=(2,1)))\n",
    "        # (64, img_height // 2, img_width // 2)\n",
    "\n",
    "        conv_relu(1)\n",
    "        cnn.add_module('pooling1', nn.MaxPool2d(kernel_size=(2,1), stride=(2,1)))\n",
    "        # (128, img_height // 4, img_width // 4)\n",
    "\n",
    "        conv_relu(2)\n",
    "        conv_relu(3)\n",
    "        cnn.add_module(\n",
    "            'pooling2',\n",
    "            nn.MaxPool2d(kernel_size=(2, 1))\n",
    "        )  # (256, img_height // 8, img_width // 4)\n",
    "\n",
    "        conv_relu(4, batch_norm=True)\n",
    "        conv_relu(5, batch_norm=True)\n",
    "        cnn.add_module(\n",
    "            'pooling3',\n",
    "            nn.MaxPool2d(kernel_size=(2, 1))\n",
    "        )  # (512, img_height // 16, img_width // 4)\n",
    "\n",
    "        conv_relu(6)  # (512, img_height // 16 - 1, img_width // 4 - 1)\n",
    "\n",
    "        output_channel, output_height, output_width = \\\n",
    "            channels[-1], img_height // 16 , img_width // 4 \n",
    "        print((output_channel, output_height, output_width))\n",
    "        return cnn, (output_channel, output_height, output_width)\n",
    "\n",
    "    def forward(self, images):\n",
    "        # shape of images: (batch, channel, height, width)\n",
    "        conv = self.cnn(images)\n",
    "        \n",
    "        # shape of conv: (batch, channel, height, width)\n",
    "        batch, channel, height, width = conv.size()\n",
    "        conv = conv.view(batch, channel * height, width)\n",
    "        conv = conv.permute(2, 0, 1)  # (width, batch, feature)\n",
    "        seq = self.map_to_seq(conv)\n",
    "        \n",
    "        recurrent, _ = self.rnn1(seq)\n",
    "        recurrent, _ = self.rnn2(recurrent)\n",
    "\n",
    "        output = self.dense(recurrent)\n",
    "        # reshape to batch, seq_length\n",
    "        output = output.transpose(0, 1)\n",
    "        return output  # shape: (seq_len, batch, num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNTrainer(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name,\n",
    "        weights=None,\n",
    "        learning_rate=0.001,\n",
    "        weight_decay=1e-4,\n",
    "        gamma=2,\n",
    "        num_classes = 223,\n",
    "        num_channels = 1,\n",
    "    ):\n",
    "        \"\"\"Initialize with pretrained weights instead of None if a pretrained model is required.\"\"\"\n",
    "        super().__init__()\n",
    "        self.training_step_losses = []\n",
    "        self.training_step_accuracy = []\n",
    "\n",
    "        self.validation_step_losses = []\n",
    "        self.validation_step_accuracy = []\n",
    "\n",
    "        self.test_step_losses = []\n",
    "\n",
    "        self.weights = weights\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.gamma = gamma\n",
    "\n",
    "        if num_classes == 2:\n",
    "            self.num_classes = num_classes - 1\n",
    "        elif num_classes > 2:\n",
    "            self.num_classes = num_classes\n",
    "\n",
    "        self.num_channels = num_channels\n",
    "\n",
    "        self.model_name = model_name\n",
    "\n",
    "        self.conv_reshape = []\n",
    "        # models ###################\n",
    "        if self.model_name == \"crnn\":\n",
    "            self.model = self._get_model()\n",
    "     \n",
    "        # possible bug with cross entropy and two classes\n",
    "\n",
    "\n",
    "        # metrics ###################\n",
    "        # self.f1 = F1Score(task=self.classification, num_classes=self.num_classes)\n",
    "        # self.auroc = AUROC(task=self.classification, num_classes=self.num_classes)\n",
    "        # self.recall = Recall(task=self.classification, num_classes=self.num_classes)\n",
    "        # self.accuracy = Accuracy(task=, num_classes=self.num_classes)\n",
    "        # self.precision = Precision(task=self.classification, num_classes=self.num_classes)\n",
    "        # self.specifity = Specificity(task=self.classification, num_classes=self.num_classes)\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def loss_fn(self, output, target):\n",
    "        # ðŸªŸ Clip the target values to be within the range [0, 1]\n",
    "        #clipped_target = torch.clip(target, min=0, max=1)\n",
    "        # ðŸ“‰ Calculate the mean squared error loss\n",
    "        \n",
    "        #mses = torch.nn.functional.l1_loss(output, clipped_target, reduction='mean')\n",
    "        mses = torch.nn.functional.l1_loss(output, target, reduction='mean')\n",
    "\n",
    "        return mses\n",
    "\n",
    "        \n",
    "    def _get_model(self):\n",
    "        model = CRNN(img_channel=1, img_width=512, img_height=512)\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "    # def _metrics(self, y_pred, y_true):\n",
    "    #     f1 = self.f1(y_pred, y_true)\n",
    "    #     auroc = self.auroc(y_pred, y_true)\n",
    "    #     recall = self.recall(y_pred, y_true)\n",
    "    #     precision = self.precision(y_pred, y_true)\n",
    "    #     accuracy = self.accuracy(y_pred, y_true)\n",
    "    #     specifity = self.specifity(y_pred, y_true)\n",
    "    #     return accuracy\n",
    "\n",
    "    def forward(self, imgs):\n",
    "        output = self.model(imgs)\n",
    "        #print(output)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "       \n",
    "        optimizer = torch.optim.Adam(\n",
    "            self.model.parameters(),\n",
    "            lr=self.learning_rate,\n",
    "            weight_decay=self.weight_decay\n",
    "        )\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, y_true, mask = batch\n",
    "        \n",
    "\n",
    "        y_pred = self.forward(inputs)\n",
    "        y_pred = y_pred * mask.unsqueeze(-1)\n",
    "        #print(mask.unique())\n",
    "        #print(y_pred.unique())       \n",
    "        # loss\n",
    "    \n",
    "        y_true = y_true.unsqueeze(-1)\n",
    "        y_true = y_true * mask.unsqueeze(-1) \n",
    "        loss = self.loss_fn(y_pred, y_true)\n",
    "\n",
    "        # accuracy = self._metrics(y_pred, y_true)\n",
    "\n",
    "        self.training_step_losses.append(loss)\n",
    "        # self.training_step_accuracy.append(accuracy)\n",
    "\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_step=True)\n",
    "        # self.log(\"train_accuracy\", accuracy, prog_bar=True, on_step=True)\n",
    "        # self.log(\"train_auroc\", auroc, prog_bar=False, on_step=True)\n",
    "        # self.log(\"train_precision\", precision, prog_bar=False, on_step=True)\n",
    "        # self.log(\"train_recall\", recall, prog_bar=False, on_step=True)\n",
    "        # self.log(\"train_f1\", f1, prog_bar=False, on_step=True)\n",
    "        # self.log(\"train_specifity\", specifity, prog_bar=False, on_step=True)\n",
    "\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        avg_loss = torch.stack(self.training_step_losses).mean()\n",
    "        # avg_train_acc = torch.stack(self.training_step_accuracy).mean()\n",
    "\n",
    "        self.log(\n",
    "            \"train_loss_epoch_end\",\n",
    "            avg_loss,\n",
    "            prog_bar=True,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "        )\n",
    "        # self.log(\n",
    "        #     \"train_acc_epoch_end\",\n",
    "        #     avg_train_acc,\n",
    "        #     prog_bar=True,\n",
    "        #     on_step=False,\n",
    "        #     on_epoch=True,\n",
    "        # )\n",
    "        return avg_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, y_true, mask = batch\n",
    "\n",
    "        y_pred = self.forward(inputs)\n",
    "        y_pred = y_pred * mask.unsqueeze(-1)\n",
    "     \n",
    "    \n",
    "        # loss\n",
    "        y_true = y_true.unsqueeze(-1)\n",
    "        y_true = y_true * mask.unsqueeze(-1) \n",
    "        loss = self.loss_fn(y_pred, y_true)\n",
    "\n",
    "        # accuracy = self._metrics(y_pred, y_true)\n",
    "\n",
    "        self.validation_step_losses.append(loss)\n",
    "        # self.validation_step_accuracy.append(accuracy)\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_step=True)\n",
    "        # self.log(\"val_accuracy\", accuracy, prog_bar=True, on_step=True)\n",
    "        # self.log(\"val_auroc\", auroc, prog_bar=False, on_step=True)\n",
    "        # self.log(\"val_precision\", precision, prog_bar=False, on_step=True)\n",
    "        # self.log(\"val_recall\", recall, prog_bar=False, on_step=True)\n",
    "        # self.log(\"val_f1\", f1, prog_bar=False, on_step=True)\n",
    "        # self.log(\"val_specifity\", specifity, prog_bar=False, on_step=True)\n",
    "\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        avg_loss = torch.stack(self.validation_step_losses).mean()\n",
    "        # avg_train_acc = torch.stack(self.validation_step_accuracy).mean()\n",
    "\n",
    "        self.log(\n",
    "            \"validation_loss_epoch_end\",\n",
    "            avg_loss,\n",
    "            prog_bar=True,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "        )\n",
    "        # self.log(\n",
    "        #     \"validation_acc_epoch_end\",\n",
    "        #     avg_train_acc,\n",
    "        #     prog_bar=True,\n",
    "        #     on_step=False,\n",
    "        #     on_epoch=True,\n",
    "        # )\n",
    "        return avg_loss\n",
    "\n",
    "    # This is for binaryCE loss cuz one dimension \n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        inputs, mask = batch\n",
    "        y_pred = self.forward(inputs)\n",
    "        y_pred = y_pred * mask.unsqueeze(-1)\n",
    "        # if self.classification == 'binary':\n",
    "        #     y_pred = torch.nn.functional.sigmoid(y_pred)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 32, 128)\n"
     ]
    }
   ],
   "source": [
    "model = CNNTrainer(\"crnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "CNNTrainer                               [64, 512, 1]              --\n",
      "â”œâ”€CRNN: 1-1                              [64, 512, 1]              --\n",
      "â”‚    â””â”€Sequential: 2-1                   [64, 512, 32, 512]        --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-1                  [64, 64, 512, 512]        640\n",
      "â”‚    â”‚    â””â”€ReLU: 3-2                    [64, 64, 512, 512]        --\n",
      "â”‚    â”‚    â””â”€MaxPool2d: 3-3               [64, 64, 256, 512]        --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-4                  [64, 128, 256, 512]       73,856\n",
      "â”‚    â”‚    â””â”€ReLU: 3-5                    [64, 128, 256, 512]       --\n",
      "â”‚    â”‚    â””â”€MaxPool2d: 3-6               [64, 128, 128, 512]       --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-7                  [64, 256, 128, 512]       295,168\n",
      "â”‚    â”‚    â””â”€ReLU: 3-8                    [64, 256, 128, 512]       --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-9                  [64, 256, 128, 512]       590,080\n",
      "â”‚    â”‚    â””â”€ReLU: 3-10                   [64, 256, 128, 512]       --\n",
      "â”‚    â”‚    â””â”€MaxPool2d: 3-11              [64, 256, 64, 512]        --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-12                 [64, 512, 64, 512]        1,180,160\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-13            [64, 512, 64, 512]        1,024\n",
      "â”‚    â”‚    â””â”€ReLU: 3-14                   [64, 512, 64, 512]        --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-15                 [64, 512, 64, 512]        2,359,808\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-16            [64, 512, 64, 512]        1,024\n",
      "â”‚    â”‚    â””â”€ReLU: 3-17                   [64, 512, 64, 512]        --\n",
      "â”‚    â”‚    â””â”€MaxPool2d: 3-18              [64, 512, 32, 512]        --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-19                 [64, 512, 32, 512]        2,359,808\n",
      "â”‚    â”‚    â””â”€ReLU: 3-20                   [64, 512, 32, 512]        --\n",
      "â”‚    â””â”€Linear: 2-2                       [512, 64, 64]             1,048,640\n",
      "â”‚    â””â”€LSTM: 2-3                         [512, 64, 512]            659,456\n",
      "â”‚    â””â”€LSTM: 2-4                         [512, 64, 512]            1,576,960\n",
      "â”‚    â””â”€Linear: 2-5                       [512, 64, 1]              513\n",
      "==========================================================================================\n",
      "Total params: 10,147,137\n",
      "Trainable params: 10,147,137\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.TERABYTES): 14.32\n",
      "==========================================================================================\n",
      "Input size (MB): 67.11\n",
      "Forward/backward pass size (MB): 73299.92\n",
      "Params size (MB): 40.59\n",
      "Estimated Total Size (MB): 73407.62\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "print(summary(model, (64, 1, 512, 512)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from config import *\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "                dirpath=CRNN_CHK_PNT,\n",
    "                monitor='val_loss',\n",
    "                save_top_k=1,\n",
    "                filename='best-{epoch}-{val_loss:.2f}'\n",
    "            )\n",
    "\n",
    "logger = TensorBoardLogger(save_dir=CRNN_LOG, name='1epoch_crnn', version=1)\n",
    "\n",
    "pl_trainer = Trainer(max_epochs = 1, accelerator='gpu', devices=1, precision=\"16-mixed\", default_root_dir=CRNN_CHK_PNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | CRNN | 10.1 M\n",
      "-------------------------------\n",
      "10.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.1 M    Total params\n",
      "40.589    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7685/7685 [51:20<00:00,  2.49it/s, v_num=1, train_loss=0.0749, val_loss_step=0.0643, val_loss_epoch=0.0729, validation_loss_epoch_end=0.0729]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7685/7685 [51:20<00:00,  2.49it/s, v_num=1, train_loss=0.0749, val_loss_step=0.0643, val_loss_epoch=0.0729, validation_loss_epoch_end=0.0729]\n"
     ]
    }
   ],
   "source": [
    "pl_trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reload your desired checkpoint\n",
    "#model = CNNTrainer.load_from_checkpoint(r\"E:\\Studies\\MAT6493\\project\\RNA_Reactivity_Prediction\\experiments\\crnn\\lightning_logs\\version_1\\checkpoints\\epoch=0-step=7685.ckpt\")\n",
    "y_pred = pl_trainer.predict(model=model, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34,\n",
       "        36, 38, 40, 42, 44, 46])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand = torch.arange(16*3).reshape(4, 4, 3)\n",
    "mask = torch.where(rand % 2 == 0)\n",
    "rand[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GNN BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders.edgecnn_dataloader import *\n",
    "from trainers.gnn_trainer import *\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from config import *\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_dataset = SimpleGraphDataset(P_TRAIN_PARQUET_QUICK, edge_distance=4)\n",
    "test_dataset = InferenceGraphDataset(P_TEST_PARQUET, edge_distance=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_dataset.num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator1 = torch.Generator().manual_seed(42)\n",
    "train_dataset, val_dataset = random_split(train_val_dataset, [0.7, 0.3], generator1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4, persistent_workers=True, pin_memory=True)  \n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4, persistent_workers=True, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[177, 4], edge_index=[2, 1396], y=[177], valid_mask=[100])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = GNNTrainer(\"edgecnn\", num_features=train_val_dataset.num_features, num_channels=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/mina/miniconda3/envs/main-env/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=EDGECNN_CHK_PNT,\n",
    "            monitor='val_loss',\n",
    "            save_top_k=1,\n",
    "            filename='best-{epoch}-{val_loss:.2f}'\n",
    "        )\n",
    "\n",
    "#logger = TensorBoardLogger(save_dir=log, name=f\"{args.num_epoch}epoch_{args.model_name}\", version=1)\n",
    "logger = TensorBoardLogger(save_dir=EDGECNN_LOG, name=f\"1epoch_crnn\", version=1)\n",
    "\n",
    "\n",
    "\n",
    "# fit the model\n",
    "pl_trainer = pl.Trainer(max_epochs = 1, accelerator='cpu', devices=1, default_root_dir=EDGECNN_CHK_PNT)\n",
    "#pl_trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
    "model = GNNTrainer.load_from_checkpoint(\"./experiments/edgecnn/lightning_logs/version_37/checkpoints/epoch=0-step=11135.ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4, persistent_workers=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0:   1%|          | 1042/86344 [00:46<1:04:07, 22.17it/s]\n",
      "Predicting: |          | 83192/? [07:58<00:00, 173.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mina/miniconda3/envs/main-env/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "predictions = pl_trainer.predict(model=model, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn.models import EdgeCNN\n",
    "device = 'cpu'\n",
    "\n",
    "# ðŸ› ï¸ Set the device to GPU if available, otherwise use CPU\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# ðŸ—ï¸ Initialize the EdgeCNN model with specified parameters\n",
    "model = EdgeCNN(\n",
    "    in_channels=train_val_dataset.num_features,  # ðŸ“Š Input features determined by the dataset\n",
    "    hidden_channels=128,  # ðŸ•³ï¸ Number of hidden channels in the model\n",
    "    num_layers=4,  # ðŸ§± Number of layers in the model\n",
    "    out_channels=1  # ðŸ“¤ Number of output channels\n",
    ").to(device)  # ðŸ—ï¸ Move the model to the selected device (GPU or CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“‰ Define loss functions for training and evaluation\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def loss_fn(output, target):\n",
    "    # ðŸªŸ Clip the target values to be within the range [0, 1]\n",
    "    clipped_target = torch.clip(target, min=0, max=1)\n",
    "    # ðŸ“‰ Calculate the mean squared error loss\n",
    "    mses = F.mse_loss(output, clipped_target, reduction='mean')\n",
    "    return mses\n",
    "\n",
    "def mae_fn(output, target):\n",
    "    # ðŸªŸ Clip the target values to be within the range [0, 1]\n",
    "    clipped_target = torch.clip(target, min=0, max=1)\n",
    "    # ðŸ“‰ Calculate the mean absolute error loss\n",
    "    maes = F.l1_loss(output, clipped_target, reduction='mean')\n",
    "    return maes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss 0.1454:   1%|          | 97/11135 [00:10<20:45,  8.86it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/mina/workspace/RNA_Reactivity_Prediction/testing.ipynb Cell 52\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mina/workspace/RNA_Reactivity_Prediction/testing.ipynb#Y102sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(out[batch\u001b[39m.\u001b[39mvalid_mask], batch\u001b[39m.\u001b[39my[batch\u001b[39m.\u001b[39mvalid_mask])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mina/workspace/RNA_Reactivity_Prediction/testing.ipynb#Y102sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m mae \u001b[39m=\u001b[39m mae_fn(out[batch\u001b[39m.\u001b[39mvalid_mask], batch\u001b[39m.\u001b[39my[batch\u001b[39m.\u001b[39mvalid_mask])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mina/workspace/RNA_Reactivity_Prediction/testing.ipynb#Y102sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mina/workspace/RNA_Reactivity_Prediction/testing.ipynb#Y102sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m train_losses\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy())\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mina/workspace/RNA_Reactivity_Prediction/testing.ipynb#Y102sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m train_maes\u001b[39m.\u001b[39mappend(mae\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/miniconda3/envs/main-env/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/main-env/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 1\n",
    "\n",
    "# ðŸ“ˆ Define the optimizer with learning rate and weight decay\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003, weight_decay=5e-4)\n",
    "\n",
    "# ðŸš‚ Iterate over epochs\n",
    "for epoch in range(n_epochs):\n",
    "    train_losses = []\n",
    "    train_maes = []\n",
    "    model.train()\n",
    "    \n",
    "    # ðŸšž Iterate over batches in the training dataloader\n",
    "    for batch in (pbar := tqdm(train_dataloader, position=0, leave=True)):\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch.x, batch.edge_index)\n",
    "        out = torch.squeeze(out)\n",
    "        loss = loss_fn(out[batch.valid_mask], batch.y[batch.valid_mask])\n",
    "        mae = mae_fn(out[batch.valid_mask], batch.y[batch.valid_mask])\n",
    "        loss.backward()\n",
    "        train_losses.append(loss.detach().cpu().numpy())\n",
    "        train_maes.append(mae.detach().cpu().numpy())\n",
    "        optimizer.step()\n",
    "        pbar.set_description(f\"Train loss {loss.detach().cpu().numpy():.4f}\")\n",
    "    \n",
    "    # ðŸ“Š Print average training loss and MAE for the epoch\n",
    "    print(f\"Epoch {epoch} train loss: \", np.mean(train_losses))\n",
    "    print(f\"Epoch {epoch} train mae: \", np.mean(train_maes))\n",
    "    \n",
    "    val_losses = []\n",
    "    val_maes = []\n",
    "    model.eval()\n",
    "    \n",
    "    # ðŸšž Iterate over batches in the validation dataloader\n",
    "    for batch in (pbar := tqdm(val_dataloader, position=0, leave=True)):\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch.x, batch.edge_index)\n",
    "        out = torch.squeeze(out)\n",
    "        loss = loss_fn(out[batch.valid_mask], batch.y[batch.valid_mask])\n",
    "        mae = mae_fn(out[batch.valid_mask], batch.y[batch.valid_mask])\n",
    "        val_losses.append(loss.detach().cpu().numpy())\n",
    "        val_maes.append(mae.detach().cpu().numpy())\n",
    "        pbar.set_description(f\"Validation loss {loss.detach().cpu().numpy():.4f}\")\n",
    "    \n",
    "    # ðŸ“Š Print average validation loss and MAE for the epoch\n",
    "    print(f\"Epoch {epoch} val loss: \", np.mean(val_losses))\n",
    "    print(f\"Epoch {epoch} val mae: \", np.mean(val_maes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
